{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages here (if necessary)\n",
    "# !pip install --upgrade pip\n",
    "# !pip install fuzzywuzzy\n",
    "# !pip install python-Levenshtein\n",
    "# !pip install gensim\n",
    "# !pip install pyemd\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Importing libraries ----\n",
      "---- Libraries imported ----\n"
     ]
    }
   ],
   "source": [
    "print('---- Importing libraries ----')\n",
    "import gensim\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from gc import collect\n",
    "from scipy import sparse\n",
    "from pprint import pprint\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from fuzzywuzzy import fuzz\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from nltk import word_tokenize\n",
    "from easygui import fileopenbox\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import stopwords\n",
    "from psutil import virtual_memory\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "print('---- Libraries imported ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Loading data ----\n",
      "No. of rows to take from data file: 100\n",
      "---- Data loaded ----\n"
     ]
    }
   ],
   "source": [
    "print('---- Loading data ----')\n",
    "data_file = fileopenbox(msg = 'DATA FILE (Ex. train.csv)',title='Browse')\n",
    "rows = int(input('No. of rows to take from data file: '))\n",
    "data = read_csv(data_file, sep=',',nrows=rows)\n",
    "data = data.drop(['id', 'qid1', 'qid2'], axis=1)\n",
    "print('---- Data loaded ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Computing basic features ----\n",
      "['len_q1',\n",
      " 'len_q2',\n",
      " 'diff_len',\n",
      " 'len_char_q1',\n",
      " 'len_char_q2',\n",
      " 'len_word_q1',\n",
      " 'len_word_q2',\n",
      " 'common_words']\n",
      "---- Computed ----\n"
     ]
    }
   ],
   "source": [
    "print('---- Computing basic features ----')\n",
    "# length based features\n",
    "data['len_q1'] = data.question1.apply(lambda x: len(str(x)))\n",
    "data['len_q2'] = data.question2.apply(lambda x: len(str(x)))\n",
    "# difference in lengths of two questions\n",
    "data['diff_len'] = data.len_q1 - data.len_q2\n",
    "\n",
    "# character length based features\n",
    "data['len_char_q1'] = data.question1.apply(lambda x: \n",
    "len(''.join(set(str(x).replace(' ', '')))))\n",
    "data['len_char_q2'] = data.question2.apply(lambda x: \n",
    "len(''.join(set(str(x).replace(' ', '')))))\n",
    "\n",
    "# word length based features\n",
    "data['len_word_q1'] = data.question1.apply(lambda x: \n",
    "len(str(x).split()))\n",
    "data['len_word_q2'] = data.question2.apply(lambda x: \n",
    "len(str(x).split()))\n",
    "\n",
    "# common words in the two questions\n",
    "data['common_words'] = data.apply(lambda x: \n",
    "len(set(str(x['question1'])\n",
    ".lower().split())\n",
    ".intersection(set(str(x['question2'])\n",
    ".lower().split()))), axis=1)\n",
    "fs_1 = ['len_q1', 'len_q2', 'diff_len', 'len_char_q1', \n",
    "        'len_char_q2', 'len_word_q1', 'len_word_q2',     \n",
    "        'common_words']\n",
    "pprint(fs_1)\n",
    "print('---- Computed ----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "60\n",
      "73\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "# examples:\n",
    "# Qratios\n",
    "print(fuzz.QRatio('Why did Trump win the Presidency?','How did Donald Trump win the 2016 Presidential Election'))\n",
    "print(fuzz.QRatio(\"How can I start an online shopping (e-commerce) website?\", \"Which web technology is best suitable for building a big E-Commerce website?\"))\n",
    "# partial ratios:\n",
    "print(fuzz.partial_ratio(\"Why did Trump win the Presidency?\",\"How did Donald Trump win the 2016 Presidential Election\"))\n",
    "print(fuzz.partial_ratio(\"How can I start an online shopping (e-commerce) website?\", \"Which web technology is best suitable for building a big E-Commerce website?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Computing fuzzy features ----\n",
      "['fuzz_qratio',\n",
      " 'fuzz_WRatio',\n",
      " 'fuzz_partial_ratio',\n",
      " 'fuzz_partial_token_set_ratio',\n",
      " 'fuzz_partial_token_sort_ratio',\n",
      " 'fuzz_token_set_ratio',\n",
      " 'fuzz_token_sort_ratio']\n",
      "---- Computed ----\n"
     ]
    }
   ],
   "source": [
    "print('---- Computing fuzzy features ----')\n",
    "data['fuzz_qratio'] = data.apply(lambda x: fuzz.QRatio(\n",
    "    str(x['question1']), str(x['question2'])), axis=1)\n",
    "data['fuzz_WRatio'] = data.apply(lambda x: fuzz.WRatio(\n",
    "str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_partial_ratio'] = data.apply(lambda x: \n",
    "fuzz.partial_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_partial_token_set_ratio'] = data.apply(lambda x:\n",
    "fuzz.partial_token_set_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_partial_token_sort_ratio'] = data.apply(lambda x: \n",
    "fuzz.partial_token_sort_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_token_set_ratio'] = data.apply(lambda x: \n",
    "fuzz.token_set_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "data['fuzz_token_sort_ratio'] = data.apply(lambda x: \n",
    "fuzz.token_sort_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "fs_2 = ['fuzz_qratio', 'fuzz_WRatio', 'fuzz_partial_ratio', \n",
    "       'fuzz_partial_token_set_ratio', 'fuzz_partial_token_sort_ratio',\n",
    "       'fuzz_token_set_ratio', 'fuzz_token_sort_ratio']\n",
    "pprint(fs_2)\n",
    "print('---- Computed ----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf and SVD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Computing features for LSA (using SVD) ----\n"
     ]
    }
   ],
   "source": [
    "print('---- Computing features for LSA (using SVD) ----')\n",
    "tfv_q1 = TfidfVectorizer(min_df=3, \n",
    "max_features=None, \n",
    "strip_accents='unicode', \n",
    "analyzer='word', \n",
    "token_pattern=r'w{1,}',\n",
    "ngram_range=(1, 2), \n",
    "use_idf=1, \n",
    "smooth_idf=1, \n",
    "sublinear_tf=1,\n",
    "stop_words='english')\n",
    "\n",
    "tfv_q2 = deepcopy(tfv_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_tfidf = tfv_q1.fit_transform(data.question1.fillna(\"\"))\n",
    "q2_tfidf = tfv_q2.fit_transform(data.question2.fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_q1 = TruncatedSVD(n_components=1)\n",
    "svd_q2 = TruncatedSVD(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_vectors = svd_q1.fit_transform(q1_tfidf)\n",
    "question2_vectors = svd_q2.fit_transform(q2_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain features by stacking the sparse matrices together\n",
    "fs3_1 = sparse.hstack((q1_tfidf, q2_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3, \n",
    "                      max_features=None, \n",
    "                      strip_accents='unicode', \n",
    "                      analyzer='word', \n",
    "                      token_pattern=r'w{1,}',\n",
    "                      ngram_range=(1, 2), \n",
    "                      use_idf=1, \n",
    "                      smooth_idf=1, \n",
    "                      sublinear_tf=1,\n",
    "                      stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine questions and calculate tf-idf\n",
    "q1q2 = data.question1.fillna(\"\") \n",
    "q1q2 += \" \" + data.question2.fillna(\"\")\n",
    "fs3_2 = tfv.fit_transform(q1q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain features by stacking the matrices together\n",
    "fs3_3 = np.hstack((question1_vectors, question2_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain features by stacking the matrices together\n",
    "x = sparse.hstack((q1_tfidf,q2_tfidf))\n",
    "svd_q1q2 = TruncatedSVD(n_components=1)\n",
    "xx = svd_q1q2.fit_transform(x)\n",
    "fs3_4 = xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Computed ----\n"
     ]
    }
   ],
   "source": [
    "# obtain features by stacking the matrices together\n",
    "x = sparse.hstack((q1_tfidf,q2_tfidf))\n",
    "svd_ff = TruncatedSVD(n_components=1)\n",
    "xx = svd_ff.fit_transform(fs3_2)\n",
    "fs3_5 = xx\n",
    "print('---- Computed ----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W2V features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Computing Word2Vec features ----\n",
      "\t---- Loading (google-news) glove vectors ----\n",
      "\t---- Enter limit for W2V vectors to load (Ex.50000 or None to load all): 100\n",
      "\t---- Model loaded ----\n"
     ]
    }
   ],
   "source": [
    "print('---- Computing Word2Vec features ----')\n",
    "print('\\t---- Loading (google-news) glove vectors ----')\n",
    "glove_vectors_file = fileopenbox(msg = 'Word2Vec FILE (Ex. xyz.bin.gz)',title='Browse')\n",
    "lim = input('\\t---- Enter limit for W2V vectors to load (Ex.50000 or None to load all): ')\n",
    "if lim == 'None':\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "else:\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True,limit=int(lim))\n",
    "print('\\t---- Model loaded ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.\n",
    "# model['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def sent2vec(s, model): \n",
    "    M = []\n",
    "    words = word_tokenize(str(s).lower())\n",
    "    for word in words:\n",
    "        #It shouldn't be a stopword, nor contain numbers, and be part of word2vec\n",
    "        if word not in stop_words and word.isalpha() and word in model:\n",
    "            M.append(model[word])\n",
    "    M = np.array(M)\n",
    "    if len(M) > 0:\n",
    "        v = M.sum(axis=0)\n",
    "        return v / np.sqrt((v ** 2).sum())\n",
    "    else:\n",
    "        return np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_q1 = np.array([sent2vec(q, model) \n",
    "                   for q in data.question1])\n",
    "w2v_q2 = np.array([sent2vec(q, model) \n",
    "                   for q in data.question2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cosine_distance'] = [cosine(x,y) \n",
    "for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "data['cityblock_distance'] = [cityblock(x,y) \n",
    "for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "data['jaccard_distance'] = [jaccard(x,y) \n",
    "for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "data['canberra_distance'] = [canberra(x,y) \n",
    "for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "data['euclidean_distance'] = [euclidean(x,y) \n",
    "for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "data['minkowski_distance'] = [minkowski(x,y,3) \n",
    "for (x,y) in zip(w2v_q1, w2v_q2)]\n",
    "data['braycurtis_distance'] = [braycurtis(x,y) \n",
    "for (x,y) in zip(w2v_q1, w2v_q2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs4_1 = ['cosine_distance', 'cityblock_distance', \n",
    "         'jaccard_distance', 'canberra_distance', \n",
    "         'euclidean_distance', 'minkowski_distance',\n",
    "         'braycurtis_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = np.hstack((w2v_q1, w2v_q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmd(s1, s2, model):\n",
    "    s1 = str(s1).lower().split()\n",
    "    s2 = str(s2).lower().split()\n",
    "    stop_words = stopwords.words('english')\n",
    "    s1 = [w for w in s1 if w not in stop_words]\n",
    "    s2 = [w for w in s2 if w not in stop_words]\n",
    "    return model.wmdistance(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t---- Calculating WMD ----')\n",
    "data['wmd'] = data.apply(lambda x: wmd(x['question1'], x['question2'], model), axis=1)\n",
    "model.init_sims(replace=True)\n",
    "data['norm_wmd'] = data.apply(lambda x: wmd(x['question1'], x['question2'], model), axis=1)\n",
    "fs4_2 = ['wmd', 'norm_wmd']\n",
    "print('\\t---- Calculated ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "['cosine_distance',\n",
      " 'cityblock_distance',\n",
      " 'jaccard_distance',\n",
      " 'canberra_distance',\n",
      " 'euclidean_distance',\n",
      " 'minkowski_distance',\n",
      " 'braycurtis_distance']\n",
      "---- Computed ----\n"
     ]
    }
   ],
   "source": [
    "pprint(fs4_1)\n",
    "print('---- Computed ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>...</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>cosine_distance</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068972</td>\n",
       "      <td>5.081614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.023324</td>\n",
       "      <td>0.371408</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.186557</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.217555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>-37</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.512164</td>\n",
       "      <td>14.195120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.588090</td>\n",
       "      <td>1.012091</td>\n",
       "      <td>0.455910</td>\n",
       "      <td>0.592655</td>\n",
       "      <td>3.772346</td>\n",
       "      <td>1.368796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>0.222009</td>\n",
       "      <td>9.055989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.988707</td>\n",
       "      <td>0.666346</td>\n",
       "      <td>0.307828</td>\n",
       "      <td>0.342306</td>\n",
       "      <td>1.780585</td>\n",
       "      <td>0.639209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>-15</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.650411</td>\n",
       "      <td>15.987436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192.237828</td>\n",
       "      <td>1.140536</td>\n",
       "      <td>0.506028</td>\n",
       "      <td>0.692421</td>\n",
       "      <td>3.741994</td>\n",
       "      <td>1.263719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>0.369993</td>\n",
       "      <td>12.103178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161.408435</td>\n",
       "      <td>0.860225</td>\n",
       "      <td>0.382770</td>\n",
       "      <td>0.480633</td>\n",
       "      <td>3.659165</td>\n",
       "      <td>1.240908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  len_q1  \\\n",
       "0  What is the step by step guide to invest in sh...             0      66   \n",
       "1  What would happen if the Indian government sto...             0      51   \n",
       "2  How can Internet speed be increased by hacking...             0      73   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0      50   \n",
       "4            Which fish would survive in salt water?             0      76   \n",
       "\n",
       "   len_q2  diff_len  len_char_q1  len_char_q2  len_word_q1  len_word_q2  ...  \\\n",
       "0      57         9           20           20           14           12  ...   \n",
       "1      88       -37           21           29            8           13  ...   \n",
       "2      59        14           25           24           14           10  ...   \n",
       "3      65       -15           19           26           11            9  ...   \n",
       "4      39        37           25           18           13            7  ...   \n",
       "\n",
       "   fuzz_token_set_ratio  cosine_distance  cityblock_distance  \\\n",
       "0                   100         0.068972            5.081614   \n",
       "1                    86         0.512164           14.195120   \n",
       "2                    66         0.222009            9.055989   \n",
       "3                    36         0.650411           15.987436   \n",
       "4                    67         0.369993           12.103178   \n",
       "\n",
       "   jaccard_distance  canberra_distance  euclidean_distance  \\\n",
       "0               1.0          94.023324            0.371408   \n",
       "1               1.0         177.588090            1.012091   \n",
       "2               1.0         135.988707            0.666346   \n",
       "3               1.0         192.237828            1.140536   \n",
       "4               1.0         161.408435            0.860225   \n",
       "\n",
       "   minkowski_distance  braycurtis_distance       wmd  norm_wmd  \n",
       "0            0.168999             0.186557  0.564615  0.217555  \n",
       "1            0.455910             0.592655  3.772346  1.368796  \n",
       "2            0.307828             0.342306  1.780585  0.639209  \n",
       "3            0.506028             0.692421  3.741994  1.263719  \n",
       "4            0.382770             0.480633  3.659165  1.240908  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting any past variables not required anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Deleting variables that are not required ----\n",
      "---- Deleted ----\n"
     ]
    }
   ],
   "source": [
    "print('---- Deleting variables that are not required ----')\n",
    "del([tfv_q1, tfv_q2, tfv, q1q2, \n",
    "     question1_vectors, question2_vectors, svd_q1, \n",
    "     svd_q2, q1_tfidf, q2_tfidf])\n",
    "del([w2v_q1, w2v_q2])\n",
    "del([model])\n",
    "collect()\n",
    "virtual_memory()\n",
    "print('---- Deleted ----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At this point, we simply recap the different features created up to now, and their meaning in terms of generated features:\n",
      "\n",
      "fs_1: List of basic features\n",
      "fs_2: List of fuzzy features\n",
      "fs3_1: Sparse data matrix of TFIDF for separated questions\n",
      "fs3_2: Sparse data matrix of TFIDF for combined questions\n",
      "fs3_3: Sparse data matrix of SVD\n",
      "fs3_4: List of SVD statistics\n",
      "fs4_1: List of w2vec distances\n",
      "fs4_2: List of wmd distances\n",
      "w2v: A matrix of transformed phrase’s Word2vec vectors by means of the Sent2Vec function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s='''\n",
    "At this point, we simply recap the different features created up to now, and their meaning in terms of generated features:\n",
    "\n",
    "fs_1: List of basic features\n",
    "fs_2: List of fuzzy features\n",
    "fs3_1: Sparse data matrix of TFIDF for separated questions\n",
    "fs3_2: Sparse data matrix of TFIDF for combined questions\n",
    "fs3_3: Sparse data matrix of SVD\n",
    "fs3_4: List of SVD statistics\n",
    "fs4_1: List of w2vec distances\n",
    "fs4_2: List of wmd distances\n",
    "w2v: A matrix of transformed phrase’s Word2vec vectors by means of the Sent2Vec function\n",
    "'''\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Making Logistic Regression model ----\n"
     ]
    }
   ],
   "source": [
    "print('---- Making Logistic Regression model ----')\n",
    "scaler = StandardScaler()\n",
    "y = data.is_duplicate.values\n",
    "y = y.astype('float32').reshape(-1, 1)\n",
    "# X = data[fs_1+fs_2+fs3_4+fs4_1+fs4_2]\n",
    "X = data[fs_1+fs_2+fs4_1+fs4_2]\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(0).values\n",
    "X = scaler.fit_transform(X)\n",
    "X = np.hstack((X, fs3_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_all, _ = y.shape\n",
    "idx = np.arange(n_all)\n",
    "np.random.shuffle(idx)\n",
    "n_split = n_all // 10\n",
    "idx_val = idx[:n_split]\n",
    "idx_train = idx[n_split:]\n",
    "x_train = X[idx_train]\n",
    "y_train = np.ravel(y[idx_train])\n",
    "x_val = X[idx_val]\n",
    "y_val = np.ravel(y[idx_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Training\n",
      "\t- Accuracy: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "logres = linear_model.LogisticRegression(C=0.1, solver='sag', max_iter=1000)\n",
    "print('\\t- Training')\n",
    "logres.fit(x_train, y_train)\n",
    "lr_preds = logres.predict(x_val)\n",
    "log_res_accuracy = np.sum(lr_preds == y_val) / len(y_val)\n",
    "print(\"\\t- Accuracy:\" ,round(log_res_accuracy*100.0,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = idx[:n_split]\n",
    "q1s = data.iloc[test_ids]['question1']\n",
    "q2s = data.iloc[test_ids]['question2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Xgb accuracy: 80.0 %\n"
     ]
    }
   ],
   "source": [
    "params = dict()\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = ['logloss', 'error']\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 4\n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(x_val, label=y_val)\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "bst = xgb.train(params, d_train, 5000, watchlist, \n",
    "                early_stopping_rounds=50, verbose_eval=False)\n",
    "xgb_preds = (bst.predict(d_valid) >= 0.5).astype(int)\n",
    "percents = bst.predict(d_valid)\n",
    "xgb_accuracy = np.sum(xgb_preds == y_val) / len(y_val)\n",
    "print(\"\\t- Xgb accuracy:\",round(xgb_accuracy*100.0,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.6, 51.47, 52.43, 38.66, 37.06, 20.96, 37.89, 22.05, 20.96, 61.05]\n"
     ]
    }
   ],
   "source": [
    "roundoff = []\n",
    "for i in percents:\n",
    "    roundoff.append(round(i*100.0,2))\n",
    "pprint(roundoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press ENTER to close application...\n"
     ]
    }
   ],
   "source": [
    "s=[]\n",
    "l = 0\n",
    "for i in test_ids:\n",
    "    s.append([str(q1s[i]),str(q2s[i]),str(roundoff[l])])\n",
    "    l+=1\n",
    "df=DataFrame(s,columns=['Q1','Q2','prediction(in %)'])\n",
    "df.to_csv('results.csv',sep=',',index=False)\n",
    "print('\\t- Results are saved in \\'results.csv\\'')\n",
    "print('---- DONE ----')\n",
    "i=input('Press ENTER to close application...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
